{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "# The below is necessary in Python 3.2.3 onwards to\n",
    "# have reproducible behavior for certain hash-based operations.\n",
    "# See these references for further details:\n",
    "# https://docs.python.org/3.4/using/cmdline.html#envvar-PYTHONHASHSEED\n",
    "# https://github.com/keras-team/keras/issues/2280#issuecomment-306959926\n",
    "my_seed = 2024\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "\n",
    "np.random.seed(my_seed)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "\n",
    "rn.seed(my_seed)\n",
    "\n",
    "# Force TensorFlow to use single thread. (to force it set the threads to 1)\n",
    "# Multiple threads are a potential source of\n",
    "# non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=0, inter_op_parallelism_threads=0)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "tf.set_random_seed(my_seed)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "rn.seed(my_seed)\n",
    "#--- all other imports\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import keras.backend\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.optimizers import SGD, Adam\n",
    "from numpy.random import seed\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "from bioinformatics_helpers.utils import get_mendelian_dataset\n",
    "from bioinformatics_helpers.utils import hingesig_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_AU_PRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'model__architecture': (100, 80)}</td>\n",
       "      <td>0.993681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'model__architecture': (100, 40)}</td>\n",
       "      <td>0.984577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'model__architecture': (100, 80, 40)}</td>\n",
       "      <td>0.979844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'model__architecture': (100, 40, 20)}</td>\n",
       "      <td>0.966692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'model__architecture': (100, 10)}</td>\n",
       "      <td>0.954238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'model__architecture': (80, 40, 20)}</td>\n",
       "      <td>0.949957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'model__architecture': (100, 80, 50, 20)}</td>\n",
       "      <td>0.938269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'model__architecture': (100,)}</td>\n",
       "      <td>0.928050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'model__architecture': (80, 20, 10)}</td>\n",
       "      <td>0.927387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'model__architecture': (40, 20)}</td>\n",
       "      <td>0.925833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        params  mean_train_AU_PRC\n",
       "7           {'model__architecture': (100, 80)}           0.993681\n",
       "8           {'model__architecture': (100, 40)}           0.984577\n",
       "16      {'model__architecture': (100, 80, 40)}           0.979844\n",
       "17      {'model__architecture': (100, 40, 20)}           0.966692\n",
       "9           {'model__architecture': (100, 10)}           0.954238\n",
       "18       {'model__architecture': (80, 40, 20)}           0.949957\n",
       "23  {'model__architecture': (100, 80, 50, 20)}           0.938269\n",
       "6              {'model__architecture': (100,)}           0.928050\n",
       "19       {'model__architecture': (80, 20, 10)}           0.927387\n",
       "10           {'model__architecture': (40, 20)}           0.925833"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read data from last expirment\n",
    "\n",
    "cv_results = pd.read_csv(\"cv_results_scaler_adam.csv\")\n",
    "cv_results.sort_values(\"mean_train_AU_PRC\", inplace=True, ascending=False)\n",
    "cv_results.head(10)[[\"params\",\"mean_train_AU_PRC\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get first 10 params\n",
    "params = {\n",
    "            \"model__architecture\": cv_results.head(10).param_model__architecture.apply(eval).values,\n",
    "            \"model__dropout_rate\": [0,0.2, 0.4, 0.6, 0.8],\n",
    "            \"model__epochs\": [150]\n",
    "         }\n",
    "#Srivastana et al 2014 suggests it's better to set the dropout rate between 0.4-0.8, but our dataset it's much different than those they used, it's worth seeing how it works\n",
    "#We put a dropout rate 0 to have an immediate comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_per_example = 26\n",
    "batch_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(architecture=(100,80), dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    weights_initializer = keras.initializers.glorot_normal(seed=my_seed)\n",
    "    bias_init = keras.initializers.RandomNormal(mean=0.1, stddev=0.05, seed=my_seed)\n",
    "    input_dim = feature_per_example\n",
    "    for units in architecture:\n",
    "        model.add(\n",
    "            Dense(\n",
    "                units,\n",
    "                input_dim = input_dim,\n",
    "                kernel_initializer = weights_initializer,\n",
    "                bias_initializer = bias_init,\n",
    "                activation=\"relu\"\n",
    "            )\n",
    "        )\n",
    "        input_dim=None # for the next layer keras infers its dimensions\n",
    "        model.add(\n",
    "            Dropout(rate=dropout_rate, seed=my_seed)\n",
    "        )\n",
    "        \n",
    "    model.add(\n",
    "        Dense(\n",
    "            1,\n",
    "            kernel_initializer=weights_initializer,\n",
    "            bias_initializer=keras.initializers.zeros(),\n",
    "            activation='sigmoid'\n",
    "    ))\n",
    "    optimizer = Adam()\n",
    "    model.compile(loss=hingesig_tf, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y = get_mendelian_dataset()\n",
    "\n",
    "def prc_score(y_true, y_pred):\n",
    "    precision, recall, _ = precision_recall_curve(y_true=y_true, probas_pred=y_pred)\n",
    "    return auc(x=recall, y=precision)\n",
    "\n",
    "scoring = {\n",
    "    'AVG_PREC': make_scorer(average_precision_score, needs_threshold=True),\n",
    "    'AU_PRC' : make_scorer(prc_score, needs_threshold=True),\n",
    "    'AU_ROC' : make_scorer(roc_auc_score, needs_threshold=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, verbose=0, shuffle=True, batch_size=batch_size, epochs=150)\n",
    "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"model\",model)])\n",
    "cv = StratifiedKFold(n_splits=5, random_state=my_seed, shuffle=True)\n",
    "grid_search = GridSearchCV(estimator=pipe,param_grid=params,\n",
    "                           scoring=scoring,\n",
    "                           return_train_score=True,\n",
    "                           cv=cv,\n",
    "                           refit=False\n",
    "                           )\n",
    "grid_search.fit(train_X, train_y)\n",
    "#saving cv_results_\n",
    "cv_results = pd.DataFrame.from_dict(grid_search.cv_results_)\n",
    "cv_results.to_csv(\"cv_results_scaler_adam_dropout_top_ten_train.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
